{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2deb2e5d",
   "metadata": {},
   "source": [
    "# Project 3D Modeling and Image Based Rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3059bb",
   "metadata": {},
   "source": [
    "## 0 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051896bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os.path\n",
    "from os import makedirs\n",
    "\n",
    "BASE_DATA_PATH = \"/Users/kobe/Documents/School/2024-2025/3D_Modeling_and_Image_Based_Rendering/project/dataset\"\n",
    "CURRENT_DATASET = BASE_DATA_PATH + \"/GrayCodes_HighRes\"\n",
    "CHESS_PATH = CURRENT_DATASET + \"/chess\"\n",
    "RAW_PATH = CURRENT_DATASET + \"/raw\"\n",
    "UNDIST_PATH = CURRENT_DATASET + \"/undistorted\"\n",
    "PATTERN_PATH = CURRENT_DATASET + \"/patterns\"\n",
    "\n",
    "if not os.path.exists(UNDIST_PATH):\n",
    "\tmakedirs(UNDIST_PATH)\n",
    "\n",
    "if not os.path.exists(PATTERN_PATH):\n",
    "\tmakedirs(PATTERN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7906008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesSortedNumeric(glob_pattern: str):\n",
    "\tfiles = glob(glob_pattern)\n",
    "\treturn sorted(files, key=lambda f: int(os.path.splitext(os.path.basename(f))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724b66e",
   "metadata": {},
   "source": [
    "## 1 Camerakalibratie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c835de2",
   "metadata": {},
   "source": [
    "### Kalibreer camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import combine_extrinsic_vecs, intrinsic_calibration\n",
    "\n",
    "chess_files = glob(f\"{CHESS_PATH}/*.jpg\")\n",
    "error, intrinsic, distortion, rotation_matrices, translation_vectors, image_size = intrinsic_calibration(chess_files, (7,9))\n",
    "extrinsics = combine_extrinsic_vecs(rotation_matrices, translation_vectors)\n",
    "\n",
    "np.savez(f\"{CURRENT_DATASET}/camCalibration.npz\", intrinsic=intrinsic, distortion=distortion, extrinsics=extrinsics, img_size=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91223047",
   "metadata": {},
   "source": [
    "### Load kalibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ed2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = np.load(f\"{CURRENT_DATASET}/camCalibration.npz\")\n",
    "intrinsic = calibration[\"intrinsic\"]\n",
    "distortion = calibration[\"distortion\"]\n",
    "extrinsics = calibration[\"extrinsics\"]\n",
    "height, width = calibration['img_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d77098",
   "metadata": {},
   "source": [
    "### Undistort alle afbeelding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c484b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from undistort import undistortAllViews\n",
    "\n",
    "undistortAllViews(RAW_PATH, UNDIST_PATH, intrinsic, distortion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54981f",
   "metadata": {},
   "source": [
    "### Visualize poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizeCameraPoints import drawCameraPoints\n",
    "\n",
    "drawCameraPoints(height, width, intrinsic, extrinsics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465820b",
   "metadata": {},
   "source": [
    "## 2 Structured Light"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1007d85",
   "metadata": {},
   "source": [
    "### Genereer patronen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrayCodeEncoder import GrayCodeEncoder\n",
    "\n",
    "\n",
    "ROWS = 1080\n",
    "COLS = 1920\n",
    "DEPTH = 10\n",
    "\n",
    "encoder = GrayCodeEncoder(ROWS, COLS, DEPTH)\n",
    "for depth, pattern in enumerate(encoder.patterns):\n",
    "\toutput_filename = f\"{PATTERN_PATH}/{depth}.jpg\"\n",
    "\tcv2.imwrite(output_filename, pattern)\n",
    "\tprint(f\"\\rSaved {os.path.basename(output_filename)}\", end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c43816e",
   "metadata": {},
   "source": [
    "### Decode graycode images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd9fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrayCodeDecoder import GrayCodeDecoder\n",
    "\n",
    "THRESHOLD = 8\n",
    "for view in os.listdir(str(UNDIST_PATH)):\n",
    "\tprint(f\"Decoding {view}...\")\n",
    "\tdecoder = GrayCodeDecoder([cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in getFilesSortedNumeric(f\"{UNDIST_PATH}/{view}/[0-9][0-9].jpg\")])\n",
    "\tcodes, mask = decoder.decode(THRESHOLD)\n",
    "\tnp.savez_compressed(f\"{CURRENT_DATASET}/{view}_decoded.npz\", codes=codes, mask=mask, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbfdda9",
   "metadata": {},
   "source": [
    "### Load decoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df04af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createViewDict(view: str):\n",
    "\tdata = np.load(f\"{CURRENT_DATASET}/{view}_decoded.npz\")\n",
    "\treturn {\n",
    "\t\t\"codes\": data[\"codes\"],\n",
    "\t\t\"mask\": data[\"mask\"],\n",
    "\t\t\"threshold\": data['threshold']\n",
    "\t}\n",
    "\n",
    "decoded_views = {\n",
    "\t f\"{view}\": createViewDict(view) for view in os.listdir(UNDIST_PATH)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0d887",
   "metadata": {},
   "source": [
    "### Find matches between views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23900025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matcher import correspond\n",
    "\n",
    "kp0, kp1, dMatches, matches = correspond(decoded_views)\n",
    "np.savez_compressed(f\"{CURRENT_DATASET}/matches.npz\", matches=matches, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa83721",
   "metadata": {},
   "source": [
    "### Load matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0624b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load(f\"{CURRENT_DATASET}/matches.npz\", allow_pickle=True)\n",
    "matches = loaded_data['matches'].item()\n",
    "loaded_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b420c",
   "metadata": {},
   "source": [
    "### Draw Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4580efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matcher import drawMatches\n",
    "\n",
    "img0 = cv2.imread(f\"{UNDIST_PATH}/view0/00.jpg\")\n",
    "img1 = cv2.imread(f\"{UNDIST_PATH}/view1/00.jpg\")\n",
    "drawMatches(matches, img0, img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678509df",
   "metadata": {},
   "source": [
    "## 3 Reconstructie Puntenwolk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390f904",
   "metadata": {},
   "source": [
    "### Essentiele matrix berekenen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b76fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeyPoints(matches):\n",
    "\tkp0 = []\n",
    "\tkp1 = []\n",
    "\tfor match in matches.values():\n",
    "\t\tkp0.append(match[0])\n",
    "\t\tkp1.append(match[1])\n",
    "\treturn np.array(kp0), np.array(kp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from essentialMatrixGeneration import generateEssentialMatrix\n",
    "\n",
    "kp0, kp1 = getKeyPoints(matches)\n",
    "essential_matrix, mask = generateEssentialMatrix(kp0, kp1, intrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"{CURRENT_DATASET}/essentialMatrix.npz\", essential=essential_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ce923",
   "metadata": {},
   "source": [
    "### Recover Pose of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poseRecovery import recoverPose\n",
    "from calibration import combine_extrinsic_vec\n",
    "\n",
    "kp0, kp1 = getKeyPoints(matches)\n",
    "rotation_cam1, translation_cam1, mask_pose = recoverPose(essential_matrix, kp0, kp1, intrinsic, mask)\n",
    "np.savez(f\"{CURRENT_DATASET}/extrinsics.npz\", view0=combine_extrinsic_vec(np.eye(3), np.zeros((3,1))), view1=combine_extrinsic_vec(rotation_cam1, translation_cam1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9cfb93",
   "metadata": {},
   "source": [
    "### Visualize poses of the cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import combine_extrinsic_vec\n",
    "from visualizeCameraPoints import drawCameraPoints\n",
    "\n",
    "cam0_extrinsic = combine_extrinsic_vec(np.eye(3), np.zeros((3,1)))\n",
    "cam1_extrinsic = combine_extrinsic_vec(rotation_cam1, translation_cam1)\n",
    "drawCameraPoints(height, width, intrinsic, [cam0_extrinsic, cam1_extrinsic])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd1946",
   "metadata": {},
   "source": [
    "### Triangulate points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from triangulation import triangulatePointsCustom\n",
    "\n",
    "kp0, kp1 = getKeyPoints(matches)\n",
    "proj0 = intrinsic @ np.hstack((np.eye(3), np.zeros((3,1))))\n",
    "proj1 = intrinsic @ np.hstack((rotation_cam1, translation_cam1))\n",
    "points_4d_hom = triangulatePointsCustom(proj0, proj1, kp0, kp1)\n",
    "np.savez(f\"{CURRENT_DATASET}/pointCloud.npz\", points=points_4d_hom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c69979",
   "metadata": {},
   "source": [
    "### Visualize triangulated points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d\n",
    "import open3d.visualization\n",
    "import open3d.cpu.pybind.utility as utility\n",
    "\n",
    "from visualizeCameraPoints import createLineSet\n",
    "\n",
    "\n",
    "points3D = points_4d_hom[:3, :] / points_4d_hom[3, :]\n",
    "\n",
    "points = utility.Vector3dVector(points3D.T)\n",
    "point_cloud = open3d.geometry.PointCloud(points)\n",
    "open3d.visualization.draw_geometries([point_cloud, createLineSet(height, width, intrinsic, cam0_extrinsic), createLineSet(height, width, intrinsic, cam1_extrinsic)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf505de8",
   "metadata": {},
   "source": [
    "## 4 Plane-Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d8825",
   "metadata": {},
   "source": [
    "### Load data needed for this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9178cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "calibration_data = np.load(f\"{CURRENT_DATASET}/camCalibration.npz\")\n",
    "height, width = calibration_data['img_size']\n",
    "intrinsic = calibration_data['intrinsic']\n",
    "point_cloud = np.load(f\"{CURRENT_DATASET}/pointCloud.npz\")['points']\n",
    "\n",
    "extrinsics = np.load(f\"{CURRENT_DATASET}/extrinsics.npz\")\n",
    "cam0_extrinsic = extrinsics['view0']\n",
    "cam0_extrinsic = np.vstack((cam0_extrinsic, [0,0,0,1]))\n",
    "cam1_extrinsic = extrinsics['view1']\n",
    "cam1_extrinsic = np.vstack((cam1_extrinsic, [0,0,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f3dfb",
   "metadata": {},
   "source": [
    "### Get depth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from planeSweep import getDepthMap, interpolateBetweenCams\n",
    "\n",
    "\n",
    "for depth in range(11):\n",
    "\tdepth_map = getDepthMap(intrinsic, interpolateBetweenCams(cam0_extrinsic, cam1_extrinsic, depth/10), point_cloud, (height, width))\n",
    "\tcv2.imwrite(f\"{CURRENT_DATASET}/depth_{depth/10}.jpg\", depth_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0a984",
   "metadata": {},
   "source": [
    "### Center of point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from planeSweep import interpolateBetweenCams\n",
    "virtual_extrinsic = interpolateBetweenCams(cam0_extrinsic, cam1_extrinsic, 0.5)\n",
    "virtual_extrinsic = np.vstack((virtual_extrinsic, [0,0,0,1]))\n",
    "\n",
    "pc_center = (point_cloud[:3, :] / point_cloud[3, :]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d8de6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = np.array([\n",
    "\t[0,0, 1],\n",
    "\t[4752,0, 1],\n",
    "\t[4752, 3168, 1],\n",
    "\t[0,3168, 1],\n",
    "], dtype=np.float64).T\n",
    "\n",
    "def screenToWorld(intrinsic, extrinsic, distance, points):\n",
    "\t\"\"\"Converts a screen space coordinate to a world space coordinate for a given distance\n",
    "\n",
    "\tArgs:\n",
    "\t\tintrinsic (3x3 matrix): The intrinsic matrix of the camera\n",
    "\t\textrinsic (4x4 matrix): The extrinsic matrix of the camera\n",
    "\t\tdistance (float): The distance from the camera the point should be\n",
    "\t\tpoints (3xN matrix): The points to transform to worldSpace\n",
    "\n",
    "\tReturns:\n",
    "\t\t4xN matrix:  The points transformed to worldspace\n",
    "\t\"\"\"\n",
    "\tintrinsic_inv = np.linalg.inv(intrinsic)\n",
    "\tPc =  intrinsic_inv @ points * np.array([distance]*4).reshape((1, 4))\n",
    "\tPc_hom = np.vstack((Pc, np.ones((1,4), dtype=np.float64)))\n",
    "\tPw_hom = np.linalg.inv(extrinsic) @ Pc_hom\n",
    "\treturn Pw_hom\n",
    "\n",
    "def worldToScreen(intrinsic, extrinsic, points):\n",
    "\t\"\"\"Transforms worldspace coordinates to screen space\n",
    "\n",
    "\tArgs:\n",
    "\t\tintrinsic (3x3 Matrix): The intrinsic matrix of the camera\n",
    "\t\textrinsic (4x4 Matrix): The extrinsic matrix of the camera\n",
    "\t\tpoints (4xN): The points to transform\n",
    "\n",
    "\tReturns:\n",
    "\t\t2xN Matrix: The transformed points\n",
    "\t\"\"\"\n",
    "\tcam = extrinsic @ points\n",
    "\tscreen = intrinsic @ cam[:3, :]\n",
    "\treturn screen[:2, :] / screen[2, :]\n",
    "\n",
    "def getDepthRangeFromPointCloud(point_cloud, extrinsic, bins):\n",
    "\tpoints = extrinsic @ point_cloud\n",
    "\tpoints = points[:-1, :] / points[-1, :]\n",
    "\tz_values = np.unique(np.round(points[-1, :], 5))\n",
    "\tbin_width = len(z_values) // bins\n",
    "\tresidual = len(z_values) % bin_width\n",
    "\treshaped = z_values[:-residual].reshape((-1, bin_width))\n",
    "\tbinned = reshaped.mean(axis=1)\n",
    "\treturn np.hstack((points[-1, 0]-1e-2, binned, z_values[-residual:].mean(), points[-1, -1]+1e-2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "701bf314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "Depthplane: 2.223, 99.03%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drawRectOnImg(img, points):\n",
    "\toutimg = img\n",
    "\tfor i in range(4):\n",
    "\t\tj = (i + 1) % 4\n",
    "\t\toutimg = cv2.line(outimg, points[:, i].astype(np.int32), points[:, j].astype(np.int32), (255, 255, 255))\n",
    "\treturn outimg\n",
    "\t\t\n",
    "\n",
    "\n",
    "interpolated_image = np.zeros((height, width))\n",
    "interpolated_image = interpolated_image.astype(np.float64)\n",
    "\n",
    "dist = np.linalg.norm(pc_center - virtual_extrinsic[:-1, -1])\n",
    "\n",
    "global_diff = np.ones_like(interpolated_image) * 255\n",
    "\n",
    "depths = getDepthRangeFromPointCloud(point_cloud, virtual_extrinsic, 100)\n",
    "print(depths.size)\n",
    "cam0_image = cv2.imread(f\"{UNDIST_PATH}/view0/00.jpg\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "cam1_image = cv2.imread(f\"{UNDIST_PATH}/view1/00.jpg\", cv2.IMREAD_GRAYSCALE).astype(np.float64)\n",
    "\n",
    "blurr_kernel = np.array([1/25] * 25).reshape((5,5))\n",
    "\n",
    "\n",
    "\n",
    "for i, depth in enumerate(depths):\n",
    "\tprint(f\"Depthplane: {depth:.3f}, {i/len(depths) * 100:.2f}%\", end='\\r')\n",
    "\t# Deproject the virtual image plane to world coordinates\n",
    "\tworld_corners = screenToWorld(intrinsic, virtual_extrinsic, depth, corners)\n",
    "\tcam0_screen = worldToScreen(intrinsic, cam0_extrinsic, world_corners)\n",
    "\tcam1_screen = worldToScreen(intrinsic, cam1_extrinsic, world_corners)\n",
    "\n",
    "\tcam0_homography, _ = cv2.findHomography(cam0_screen.T, corners[:-1, :].T)\n",
    "\tcam1_homography, _ = cv2.findHomography(cam1_screen.T, corners[:-1, :].T)\n",
    "\n",
    "\n",
    "\tcam0_image_persp = cv2.warpPerspective(cam0_image, cam0_homography, (4752, 3168))\n",
    "\tcam0_image_persp_blur = cv2.filter2D(cam0_image_persp, -1, blurr_kernel)\n",
    "\tcam1_image_persp = cv2.warpPerspective(cam1_image, cam1_homography, (4752, 3168))\n",
    "\tcam1_image_persp_blur = cv2.filter2D(cam1_image_persp, -1, blurr_kernel)\n",
    "\n",
    "\tdiff = cv2.absdiff(cam0_image_persp, cam1_image_persp)\n",
    "\tindices = (global_diff > diff) # & (diff < 50)\n",
    "\tglobal_diff[indices] = diff[indices]\n",
    "\tinterpolated_image[indices] = (cam0_image_persp[indices] + cam1_image_persp[indices]) / 2\n",
    "\n",
    "print()\n",
    "cv2.imwrite(f\"{CURRENT_DATASET}/interpolated_plane_depth.jpg\", interpolated_image.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometries = [point_cloud]\n",
    "\n",
    "sphere = open3d.geometry.TriangleMesh.create_sphere(0.1, 20)\n",
    "sphere.translate(pc_center)\n",
    "geometries.append(sphere)\n",
    "cam0_lineSet = createLineSet(height, width, intrinsic, cam0_extrinsic)\n",
    "geometries.append(cam0_lineSet)\n",
    "cam1_lineSet = createLineSet(height, width, intrinsic, cam1_extrinsic)\n",
    "geometries.append(cam1_lineSet)\n",
    "edges = lines = np.array([\n",
    "        [0, 1],  # Edge 1\n",
    "        [1, 2],  # Edge 2\n",
    "        [2, 3],  # Edge 3\n",
    "        [3, 0]   # Edge 4 (closes the rectangle)\n",
    "    ])\n",
    "# projected_area = open3d.geometry.LineSet(utility.Vector3dVector(Pw.T), utility.Vector2iVector(edges))\n",
    "# geometries.append(projected_area)\n",
    "# for i in range(1, 10):\n",
    "#     geometries.append(createLineSet(height, width, intrinsic, interpolateBetweenCams(cam0_extrinsic, cam1_extrinsic, i / 10)))\n",
    "geometries.append(createLineSet(height, width, intrinsic, virtual_extrinsic))\n",
    "    \n",
    "open3d.visualization.draw_geometries(geometries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda06205",
   "metadata": {},
   "source": [
    "## 5 Eigen Dataset Capteren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c14e1c",
   "metadata": {},
   "source": [
    "## 6 Reconstrucite Camera-Camera-Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dee87a",
   "metadata": {},
   "source": [
    "## 7 Light Field Displays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
